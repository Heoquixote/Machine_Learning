{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Machine Learning 프로젝트 수행을 위한 코드 구조화\n\n`(분류, 회귀 Task)`","metadata":{"id":"8f3119aa"}},{"cell_type":"markdown","source":"- ML project를 위해서 사용하는 템플릿 코드를 만듭니다.\n\n1. **필요한 라이브러리와 데이터를 불러옵니다.**\n\n\n2. **EDA를 수행합니다.** 이 때 EDA의 목적은 풀어야하는 문제를 위해서 수행됩니다.\n\n\n3. **전처리를 수행합니다.** 이 때 중요한건 **feature engineering**을 어떻게 하느냐 입니다.\n\n\n4. **데이터 분할을 합니다.** 이 때 train data와 test data 간의 분포 차이가 없는지 확인합니다.\n\n\n5. **학습을 진행합니다.** 어떤 모델을 사용하여 학습할지 정합니다. 성능이 잘 나오는 GBM을 추천합니다.\n\n\n6. **hyper-parameter tuning을 수행합니다.** 원하는 목표 성능이 나올 때 까지 진행합니다. 검증 단계를 통해 지속적으로 **overfitting이 되지 않게 주의**하세요.\n\n\n7. **최종 테스트를 진행합니다.** 데이터 분석 대회 포맷에 맞는 submission 파일을 만들어서 성능을 확인해보세요.","metadata":{"id":"9f7610ea"}},{"cell_type":"markdown","source":"## 1. 라이브러리, 데이터 불러오기","metadata":{"id":"bd2f7530"}},{"cell_type":"code","source":"                            # 데이터분석 4종 세트\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 모델들, 성능 평가\n# (저는 일반적으로 정형데이터로 머신러닝 분석할 때는 이 2개 모델은 그냥 돌려봅니다. 특히 RF가 테스트하기 좋습니다.)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm.sklearn import LGBMClassifier\nfrom lightgbm.sklearn import LGBMRegressor\n\n# 상관관계 분석, VIF : 다중공선성 제거\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# KFold(CV), partial : optuna를 사용하기 위함\nfrom sklearn.model_selection import KFold\nfrom functools import partial\n\n# hyper-parameter tuning을 위한 라이브러리, optuna\nimport optuna","metadata":{"id":"125fc348","execution":{"iopub.status.busy":"2022-08-01T10:17:56.125336Z","iopub.execute_input":"2022-08-01T10:17:56.125863Z","iopub.status.idle":"2022-08-01T10:17:56.133408Z","shell.execute_reply.started":"2022-08-01T10:17:56.125821Z","shell.execute_reply":"2022-08-01T10:17:56.132045Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# flag setting\ndata_reducing = False ## memory reducing technique\nfeature_reducing = False ## feature extraction (curse of dimensionality)","metadata":{"id":"0e4d49ce","execution":{"iopub.status.busy":"2022-08-01T10:17:56.135855Z","iopub.execute_input":"2022-08-01T10:17:56.136681Z","iopub.status.idle":"2022-08-01T10:17:56.146083Z","shell.execute_reply.started":"2022-08-01T10:17:56.136638Z","shell.execute_reply":"2022-08-01T10:17:56.144857Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"# 데이터를 불러옵니다.\ntrain = pd.read_csv('../input/dacon-elec-usage-prediction/train.csv', encoding='cp949',\n                   parse_dates=[\"date_time\"])\ntest = pd.read_csv('../input/dacon-elec-usage-prediction/test.csv', encoding='cp949',\n                  parse_dates=[\"date_time\"])","metadata":{"id":"3615c24a","execution":{"iopub.status.busy":"2022-08-01T10:17:56.147675Z","iopub.execute_input":"2022-08-01T10:17:56.148338Z","iopub.status.idle":"2022-08-01T10:17:56.332412Z","shell.execute_reply.started":"2022-08-01T10:17:56.148305Z","shell.execute_reply":"2022-08-01T10:17:56.331235Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.333699Z","iopub.execute_input":"2022-08-01T10:17:56.334062Z","iopub.status.idle":"2022-08-01T10:17:56.342238Z","shell.execute_reply.started":"2022-08-01T10:17:56.334031Z","shell.execute_reply":"2022-08-01T10:17:56.341074Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"train.columns = ['num','date_time', 'target', 'temperature', 'windspeed',\n                'humidity', 'precipitation', 'insolation',\n                'cool_flag', 'solar_flag']\ntest.columns = ['num','date_time', 'temperature', 'windspeed',\n                'humidity', 'precipitation', 'insolation',\n                'cool_flag', 'solar_flag']","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.345100Z","iopub.execute_input":"2022-08-01T10:17:56.345871Z","iopub.status.idle":"2022-08-01T10:17:56.354102Z","shell.execute_reply.started":"2022-08-01T10:17:56.345824Z","shell.execute_reply":"2022-08-01T10:17:56.352227Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"## 2. EDA","metadata":{"id":"c9c9acb8"}},{"cell_type":"markdown","source":"- 데이터에서 찾아야 하는 기초적인 내용들을 확인합니다.\n\n\n- class imbalance, target distribution, outlier, correlation을 확인합니다.","metadata":{"id":"6fdf620b"}},{"cell_type":"code","source":"## On your Own\n## 1. 데이터 크기 확인\n\n\n## 2. 결측치 확인\n\n\n## 3. dtype이 object인 column 확인\n\n\n\n## 4. target distribution\n## Q1. target value가 튀는 데이터는 없나요?\n## Q2. target value의 평균은 얼마인가요?\n## Q3. 122400개의 데이터에 대해서 target value의 평균을 보는게 의미가 있을까요?\n## Q4. 건물별 전력사용량이 가장 높은 건물은 무엇인가요?\n## Q5. 요일 별 전력사용량의 패턴이 비슷한가요?\n...\n...","metadata":{"id":"adb06474","execution":{"iopub.status.busy":"2022-08-01T10:17:56.355399Z","iopub.execute_input":"2022-08-01T10:17:56.355970Z","iopub.status.idle":"2022-08-01T10:17:56.372375Z","shell.execute_reply.started":"2022-08-01T10:17:56.355886Z","shell.execute_reply":"2022-08-01T10:17:56.371116Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nsns.lineplot(data=train, x=\"date_time\", y=\"target\", ci=None)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.373970Z","iopub.execute_input":"2022-08-01T10:17:56.375076Z","iopub.status.idle":"2022-08-01T10:17:56.805717Z","shell.execute_reply.started":"2022-08-01T10:17:56.375028Z","shell.execute_reply":"2022-08-01T10:17:56.804453Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"#for n in train.num.unique():\n#    building = train[train.num == n]\n#    plt.figure(figsize=(16, 6))\n#    plt.title(f\"\\nEnergy Usage Pattern in Building No.{n}\", fontsize=12)\n#    sns.lineplot(data=building, x=\"date_time\", y=\"target\")\n#    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.807041Z","iopub.execute_input":"2022-08-01T10:17:56.807378Z","iopub.status.idle":"2022-08-01T10:17:56.812332Z","shell.execute_reply.started":"2022-08-01T10:17:56.807348Z","shell.execute_reply":"2022-08-01T10:17:56.811102Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"markdown","source":"이런 식으로 여러가지 그래프를 그려가며, 데이터에 대한 인사이트를 얻습니다!","metadata":{"id":"f2c602bd"}},{"cell_type":"markdown","source":"### 3. 전처리","metadata":{"id":"9dbb8802"}},{"cell_type":"markdown","source":"#### 결측치 처리\n\n\n1) 건물 정보\n- 비전기냉방설비운영 / 태양광보유\n\n\n- train data의 건물 정보가 바뀌는가?  ----->  test data의 건물 정보가 바뀌었는가?\n\n\n> 만약에, train, test 데이터가 모두 건물 정보에서 변함이 없다면, 모두 같은 값으로 채워준다.\n\n> 만약에, train, test 데이터가 건물 정보에서 변화가 있다면, 언제 바뀌었는지 체크를 한다.","metadata":{"id":"b79a6f0a"}},{"cell_type":"code","source":"# 건물 정보 확인\n# 1. train data의 건물 정보가 변하는지 확인   (변하지 않음을 확인!)\nbuilding_info = train[[\"num\", \"cool_flag\", \"solar_flag\"]].drop_duplicates()\nbuilding_info","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.814174Z","iopub.execute_input":"2022-08-01T10:17:56.814616Z","iopub.status.idle":"2022-08-01T10:17:56.851399Z","shell.execute_reply.started":"2022-08-01T10:17:56.814581Z","shell.execute_reply":"2022-08-01T10:17:56.850531Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# 2. test data에서 건물 정보가 변하는지 체크\nbuilding_test = test[[\"num\", \"cool_flag\", \"solar_flag\"]]\ntest_cool = test.loc[~test.cool_flag.isnull(), [\"num\", \"cool_flag\"]]\ntest_solar = test.loc[~test.solar_flag.isnull(), [\"num\", \"solar_flag\"]]","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.855899Z","iopub.execute_input":"2022-08-01T10:17:56.856246Z","iopub.status.idle":"2022-08-01T10:17:56.866488Z","shell.execute_reply.started":"2022-08-01T10:17:56.856218Z","shell.execute_reply":"2022-08-01T10:17:56.865322Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"test_cool = test_cool.drop_duplicates()\ntest_solar = test_solar.drop_duplicates()\n#pd.merge(building_info, test_cool, on=\"num\")  ## INNER JOIN\ntemp = pd.merge(building_info, test_solar, on=\"num\")\ntemp2 = pd.merge(building_info, test_cool, on=\"num\")\n(temp.solar_flag_x == temp.solar_flag_y).mean()\n(temp2.cool_flag_x == temp2.cool_flag_y).mean()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.868323Z","iopub.execute_input":"2022-08-01T10:17:56.868743Z","iopub.status.idle":"2022-08-01T10:17:56.887706Z","shell.execute_reply.started":"2022-08-01T10:17:56.868713Z","shell.execute_reply":"2022-08-01T10:17:56.886916Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"# building_info <---> test\ntest = test.drop(columns=[\"cool_flag\", \"solar_flag\"])\ntest","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.888881Z","iopub.execute_input":"2022-08-01T10:17:56.889369Z","iopub.status.idle":"2022-08-01T10:17:56.911060Z","shell.execute_reply.started":"2022-08-01T10:17:56.889334Z","shell.execute_reply":"2022-08-01T10:17:56.909897Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"# INNER JOIN으로 cool_flag와 solar_flag를 채워줍니다.\ntest = pd.merge(test, building_info, on=\"num\")\ntest","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.912535Z","iopub.execute_input":"2022-08-01T10:17:56.912896Z","iopub.status.idle":"2022-08-01T10:17:56.939483Z","shell.execute_reply.started":"2022-08-01T10:17:56.912855Z","shell.execute_reply":"2022-08-01T10:17:56.938354Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"markdown","source":"2) 기상 정보\n\n\n- 시간에 따른 정보의 흐름이 있는 데이터이기 때문에(시계열 데이터), 쿨하게 85일치의 평균값으로 채워주면 안됩니다.\n\n\n- 대신에 데이터의 흐름을 보고 맞게 채워주는 방식을 선택하려고 합니다.\n\n\n- 선형 보간법(linear interpolation)을 사용해서 결측치를 채웁니다.","metadata":{}},{"cell_type":"code","source":"test.temperature = test.temperature.interpolate(method=\"linear\")\ntest.windspeed = test.windspeed.interpolate(method=\"linear\")\ntest.humidity = test.humidity.interpolate(method=\"linear\")\ntest.precipitation = test.precipitation.interpolate(method=\"linear\")\ntest.insolation = test.insolation.interpolate(method=\"linear\")\ntest","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.940849Z","iopub.execute_input":"2022-08-01T10:17:56.941288Z","iopub.status.idle":"2022-08-01T10:17:56.974239Z","shell.execute_reply.started":"2022-08-01T10:17:56.941253Z","shell.execute_reply":"2022-08-01T10:17:56.973141Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:56.975918Z","iopub.execute_input":"2022-08-01T10:17:56.976213Z","iopub.status.idle":"2022-08-01T10:17:56.993624Z","shell.execute_reply.started":"2022-08-01T10:17:56.976188Z","shell.execute_reply":"2022-08-01T10:17:56.992675Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":"#### Time feature\n\n- 월, 일, 요일, 시간 정보를 date_time column으로 부터 생성합니다.","metadata":{"id":"JdO_MINum6pR"}},{"cell_type":"code","source":"train[\"month\"] = train.date_time.dt.month\ntrain[\"day\"] = train.date_time.dt.day\ntrain[\"hour\"] = train.date_time.dt.hour\ntrain[\"dow\"] = train.date_time.dt.dayofweek\n\ntest[\"month\"] = test.date_time.dt.month\ntest[\"day\"] = test.date_time.dt.day\ntest[\"hour\"] = test.date_time.dt.hour\ntest[\"dow\"] = test.date_time.dt.dayofweek","metadata":{"id":"tNT9eZB0nAmq","execution":{"iopub.status.busy":"2022-08-01T10:17:56.994952Z","iopub.execute_input":"2022-08-01T10:17:56.995482Z","iopub.status.idle":"2022-08-01T10:17:57.064668Z","shell.execute_reply.started":"2022-08-01T10:17:56.995451Z","shell.execute_reply":"2022-08-01T10:17:57.063299Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"markdown","source":"#### feature extraction\n\n- 차원의 저주를 해결하거나, 데이터의 feature 조합을 이용하는 새로운 feature를 생성할 때, PCA를 사용합니다.\n\n- 분석에 사용할 feature를 선택하는 과정도 포함합니다.","metadata":{"id":"606493f0"}},{"cell_type":"code","source":"# PCA 적용\nfrom sklearn.decomposition import PCA\n\nif feature_reducing:\n    pca = PCA(n_components=0.9) # PCA(n_components=6)\n    pca_data = pca.fit_transform(X)","metadata":{"id":"4a137c94","execution":{"iopub.status.busy":"2022-08-01T10:17:57.066582Z","iopub.execute_input":"2022-08-01T10:17:57.066927Z","iopub.status.idle":"2022-08-01T10:17:57.071817Z","shell.execute_reply.started":"2022-08-01T10:17:57.066900Z","shell.execute_reply":"2022-08-01T10:17:57.070912Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"markdown","source":"### 4. 학습 데이터 분할","metadata":{"id":"f497a2d8"}},{"cell_type":"markdown","source":"과제는 해당 코드를 기반으로, 서로 나뉘어져있는 데이터를 따로 학습을 하여 2개의 학습 모델을 만들고, 두 개의 예측 결과를 합쳐서 submission.csv를 만드는 것입니다.\n3, 9, 15번 건물 데이터는 10,000개보다 적으므로 RandomForest를 이용하여 학습하고, 나머지 데이터는 LGBM으로 학습을 진행합니다.\n예측을 수행할 때는 건물별로 나뉘는 ID를 토대로 다른 모델을 사용하여 예측 결과를 만들어야 합니다.","metadata":{}},{"cell_type":"code","source":"# 첫번째 테스트용으로 사용하고, 실제 학습시에는 K-Fold CV를 사용합니다.\n# train : test = 8 : 2\nfrom sklearn.model_selection import train_test_split\n\n# 건물 번호가 3, 9, 15인 train data\ntrain_3915 = train[train.num.isin([3, 9, 15])]\n# 나머지\ntrain_ = train[~train.num.isin([3, 9, 15])]\n\nX_3915 = train_3915.drop(columns=[\"num\", \"date_time\", \"target\"])\ny_3915 = train_3915.target\n\nX = train_.drop(columns=[\"num\", \"date_time\", \"target\"])\ny = train_.target\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(X_3915.shape, X.shape, y_3915.shape, y.shape)","metadata":{"id":"47306aaf","execution":{"iopub.status.busy":"2022-08-01T10:17:57.073267Z","iopub.execute_input":"2022-08-01T10:17:57.073609Z","iopub.status.idle":"2022-08-01T10:17:57.105796Z","shell.execute_reply.started":"2022-08-01T10:17:57.073580Z","shell.execute_reply":"2022-08-01T10:17:57.104627Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"# 테스트용 데이터 나누기\n\n# 건물 번호가 3, 9, 15인 train data\ntest_3915 = test[test.num.isin([3, 9, 15])]\n# 나머지\ntest_ = test[~test.num.isin([3, 9, 15])]\n\nX_test_3915 = test_3915.drop(columns=[\"num\", \"date_time\"])\n\nX_test = test_.drop(columns=[\"num\", \"date_time\"])\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(X_test_3915.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:17:57.107169Z","iopub.execute_input":"2022-08-01T10:17:57.107493Z","iopub.status.idle":"2022-08-01T10:17:57.119708Z","shell.execute_reply.started":"2022-08-01T10:17:57.107463Z","shell.execute_reply":"2022-08-01T10:17:57.118588Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"### 5. 학습 및 평가","metadata":{"id":"58056e51"}},{"cell_type":"code","source":"# metric은 그때마다 맞게 바꿔줘야 합니다.\ndef smape(target, preds):\n    '''\n    Function to calculate SMAPE\n    '''\n    n = len(preds)\n    masked_arr = ~((preds==0)&(target==0))\n    preds, target = preds[masked_arr], target[masked_arr]\n    num = np.abs(preds-target)\n    denom = np.abs(preds)+np.abs(target)\n    smape_val = (200*np.sum(num/denom))/n\n    return smape_val\n\nevaluation_metric = smape\n#evaluation_metric = mean_absolute_percentage_error","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:41:45.473960Z","iopub.execute_input":"2022-08-01T10:41:45.474406Z","iopub.status.idle":"2022-08-01T10:41:45.482659Z","shell.execute_reply.started":"2022-08-01T10:41:45.474375Z","shell.execute_reply":"2022-08-01T10:41:45.481641Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"# 간단하게 LightGBM 테스트\n# 적당한 hyper-parameter 조합을 두었습니다. (항상 best는 아닙니다. 예시입니다.)\n\nparam_grid = {\n    \"max_bin\" : 20,\n    \"learning_rate\" : 0.0025,\n    \"objective\" : \"regression\",\n    \"boosting_type\" : \"gbdt\",\n    \"metric\" : \"mae\",\n    \"sub_feature\" : 0.345,\n    \"bagging_fraction\" : 0.85,\n    \"bagging_freq\" : 40,\n    \"num_leaves\" : 512,\n    \"min_data\" : 500,\n    \"min_hessian\" : 0.05,\n    \"verbose\" : 2,\n    \"feature_fraction_seed\" : 2,\n    \"bagging_seed\" : 3\n}\n\nmodel = LGBMRegressor(**param_grid)","metadata":{"id":"39fd2515","execution":{"iopub.status.busy":"2022-08-01T09:42:52.864625Z","iopub.execute_input":"2022-08-01T09:42:52.865708Z","iopub.status.idle":"2022-08-01T09:42:52.872448Z","shell.execute_reply.started":"2022-08-01T09:42:52.865658Z","shell.execute_reply":"2022-08-01T09:42:52.871019Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"print(\"\\nFitting LightGBM...\")\nmodel.fit(X, y)","metadata":{"scrolled":true,"id":"ddffa474","execution":{"iopub.status.busy":"2022-08-01T09:43:12.883924Z","iopub.execute_input":"2022-08-01T09:43:12.884283Z","iopub.status.idle":"2022-08-01T09:43:14.257585Z","shell.execute_reply.started":"2022-08-01T09:43:12.884256Z","shell.execute_reply":"2022-08-01T09:43:14.256829Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"gcv.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:27:59.551617Z","iopub.execute_input":"2022-08-01T10:27:59.552024Z","iopub.status.idle":"2022-08-01T10:27:59.560570Z","shell.execute_reply.started":"2022-08-01T10:27:59.551992Z","shell.execute_reply":"2022-08-01T10:27:59.559412Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"# metric은 그때마다 맞게 바꿔줘야 합니다.\nevaluation_metric = ","metadata":{"id":"6c8b0259","execution":{"iopub.status.busy":"2022-08-01T10:27:41.433197Z","iopub.execute_input":"2022-08-01T10:27:41.433612Z","iopub.status.idle":"2022-08-01T10:27:41.440507Z","shell.execute_reply.started":"2022-08-01T10:27:41.433579Z","shell.execute_reply":"2022-08-01T10:27:41.438830Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"print(\"Prediction with Best Estimator\")\ngcv_pred_train = gcv.predict(X_3915)\n#pred_test = model.predict(x_test)\n\n\ngcv_train_score = evaluation_metric(y_3915, pred_train)\n#test_score = evaluation_metric(y_test, pred_test)\n\nprint(\"Train Score : %.4f\" % train_score)\n#print(\"Test Score : %.4f\" % test_score)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T10:30:14.925579Z","iopub.execute_input":"2022-08-01T10:30:14.925961Z","iopub.status.idle":"2022-08-01T10:30:15.001291Z","shell.execute_reply.started":"2022-08-01T10:30:14.925931Z","shell.execute_reply":"2022-08-01T10:30:14.999688Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"print(\"Prediction\")\npred_train = model.predict(X_3915)\n#pred_test = model.predict(x_test)\n\n\ntrain_score = evaluation_metric(y_3915, pred_train)\n#test_score = evaluation_metric(y_test, pred_test)\n\nprint(\"Train Score : %.4f\" % train_score)\nprint(\"Test Score : %.4f\" % test_score)","metadata":{"id":"a6b39be5","execution":{"iopub.status.busy":"2022-08-01T10:27:36.828558Z","iopub.execute_input":"2022-08-01T10:27:36.829732Z","iopub.status.idle":"2022-08-01T10:27:36.880602Z","shell.execute_reply.started":"2022-08-01T10:27:36.829691Z","shell.execute_reply":"2022-08-01T10:27:36.878670Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Hyper-parameter Tuning","metadata":{"id":"bc755b17"}},{"cell_type":"markdown","source":"> GridSearchCV","metadata":{"id":"60070d0e"}},{"cell_type":"markdown","source":"** LightGBM의 hyperparameter **\n\n[Official Documentation] https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html \n\n[Blog 1] https://smecsm.tistory.com/133\n\n[Blog 2] https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5\n\n[Blog 3] https://nurilee.com/2020/04/03/lightgbm-definition-parameter-tuning/","metadata":{"id":"2bf886a9"}},{"cell_type":"code","source":"# GridSearchCV를 이용하여 가장 좋은 성능을 가지는 모델을 찾아봅시다. (이것은 첫번째엔 선택입니다.)\n# Lightgbm은 hyper-parameter의 영향을 많이 받기 때문에, 저는 보통 맨처음에 한번 정도는 가볍게 GCV를 해봅니다.\n# 성능 향상이 별로 없다면, lightgbm으로 돌린 대략적인 성능이 이 정도라고 생각하면 됩니다.\n# 만약 성능 향상이 크다면, 지금 데이터는 hyper-parameter tuning을 빡빡하게 하면 성능 향상이 많이 이끌어 낼 수 있습니다.\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    \"max_depth\" : [16, None],\n    \"n_estimators\" : [100, 300],\n    \"max_bin\" : [20],\n    \"learning_rate\" : [0.001, 0.003],\n    \"objective\" : [\"regression\"],\n    \"boosting_type\" : [\"gbdt\"],\n    \"metric\" : [\"mae\"],\n    \"sub_feature\" : [0.345],\n    \"bagging_fraction\" : [0.7, 0.75, 0.85],\n    \"bagging_freq\" : [40],\n    \"num_leaves\" : [256, 512],\n    \"min_data\" : [500],\n    \"verbose\" : [-1], # 필수\n    \"min_hessian\" : [0.05],\n    \"feature_fraction_seed\" : [2],\n    \"bagging_seed\" : [3]\n}\n\n\ngcv = GridSearchCV(estimator=model, param_grid=param_grid, cv=5,\n                  n_jobs=-1, verbose=1)\n\ngcv.fit(X_3915, y_3915)\nprint(\"Best Estimator : \", gcv.best_estimator_)","metadata":{"scrolled":true,"id":"815dcbef","execution":{"iopub.status.busy":"2022-08-01T10:39:16.246631Z","iopub.execute_input":"2022-08-01T10:39:16.247504Z","iopub.status.idle":"2022-08-01T10:39:32.057553Z","shell.execute_reply.started":"2022-08-01T10:39:16.247463Z","shell.execute_reply":"2022-08-01T10:39:32.056563Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"print(\"Prediction with Best Estimator\")\ngcv_pred_train = gcv.predict(X_3915)\n#gcv_pred_test = gcv.predict(x_test)\n\ngcv_train_score = evaluation_metric(y_3915, gcv_pred_train)\n#gcv_test_score = evaluation_metric(y_test, gcv_pred_test)\n\nprint(\"Train MAE Score : %.4f\" % gcv_train_score)\n#print(\"Test MAE Score : %.4f\" % gcv_test_score)","metadata":{"id":"9ec6ac14","execution":{"iopub.status.busy":"2022-08-01T10:42:16.336224Z","iopub.execute_input":"2022-08-01T10:42:16.336614Z","iopub.status.idle":"2022-08-01T10:42:16.376605Z","shell.execute_reply.started":"2022-08-01T10:42:16.336583Z","shell.execute_reply":"2022-08-01T10:42:16.375433Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"print(\"Performance Gain\") # 이걸로 성능 향상 확인.\nprint(\"in train : \", (train_score - gcv_train_score))\n#print(\"in test : \", (test_score - gcv_test_score))","metadata":{"id":"3b852da7","execution":{"iopub.status.busy":"2022-08-01T10:42:18.646176Z","iopub.execute_input":"2022-08-01T10:42:18.647009Z","iopub.status.idle":"2022-08-01T10:42:18.669181Z","shell.execute_reply.started":"2022-08-01T10:42:18.646946Z","shell.execute_reply":"2022-08-01T10:42:18.667953Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":"> optuna를 사용해봅시다 !","metadata":{"id":"97e5302d"}},{"cell_type":"code","source":"def optimizer(trial, X, y, K):\n    # 조절할 hyper-parameter 조합을 적어줍니다.\n    n_estimators = \n    max_depth = \n    max_features = \n    \n    \n    # 원하는 모델을 지정합니다, optuna는 시간이 오래걸리기 때문에 저는 보통 RF로 일단 테스트를 해본 뒤에 LGBM을 사용합니다.\n    model = RandomForestRegressor(n_estimators=n_estimators,\n                                 max_depth=max_depth,\n                                 max_features=max_features)\n    \n    \n    # K-Fold Cross validation을 구현합니다.\n    folds = KFold(n_splits=K)\n    losses = []\n    \n    for train_idx, val_idx in folds.split(X, y):\n        X_train = X.iloc[train_idx, :]\n        y_train = y.iloc[train_idx]\n        \n        X_val = X.iloc[val_idx, :]\n        y_val = y.iloc[val_idx]\n        \n        model.fit(X_train, y_train)\n        preds = model.predict(X_val)\n        loss = mean_absolute_error(y_val, preds)\n        losses.append(loss)\n    \n    \n    # K-Fold의 평균 loss값을 돌려줍니다.\n    return np.mean(losses)","metadata":{"id":"34ce4986"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K = # Kfold 수\nopt_func = partial(optimizer, X=X_train, y=y_train, K)\n\nstudy = optuna.create_study(direction=\"minimize\") # 최소/최대 어느 방향의 최적값을 구할 건지.\nstudy.optimize(opt_func, n_trials=5)","metadata":{"id":"7150b210"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optuna가 시도했던 모든 실험 관련 데이터\nstudy.trials_dataframe()","metadata":{"id":"72d0a118"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best Score: %.4f\" % study.best_value) # best score 출력\nprint(\"Best params: \", study.best_trial.params) # best score일 때의 하이퍼파라미터들","metadata":{"id":"a805da05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 실험 기록 시각화\noptuna.visualization.plot_optimization_history(study)","metadata":{"id":"051ae1eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyper-parameter들의 중요도\noptuna.visualization.plot_param_importances(study)","metadata":{"id":"efbf8f65"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. 테스트 및 제출 파일 생성","metadata":{"id":"24b360ec"}},{"cell_type":"code","source":"model = RandomForestRegressor(n_estimators=study.best_trial.params[\"n_estimators\"],\n                                 max_depth=study.best_trial.params[\"max_depth\"],\n                                 max_features=study.best_trial.params[\"max_features\"])\n\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\npreds","metadata":{"id":"a0daf54e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test # 원본 데이터랑 id가 맞는지 확인 해보기!","metadata":{"id":"dfa0db70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame() # submission을 생성합니다.\nsubmission","metadata":{"id":"8ff2070c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.reset_index(drop=True).to_csv(\"submission.csv\", index=False)","metadata":{"id":"55a2c13f"},"execution_count":null,"outputs":[]}]}